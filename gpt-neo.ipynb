{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT-Neo 작문 환경 설정\n",
    "\n",
    "\n",
    "허깅페이스 모델 헙(huggingface.co/models)에는 EleutherAI/gpt-neorepository에 의해 공개된 사전학습모델인 ElutherAI/gpt-neo-1.3B 모델이 있습니다. 이는 GPT2 or GPT3의 오픈소스 버전이며 이를 사용하기 위해 관련 라이브러리인 트랜스포머와 sentencepice를 설치하세요 그리고 모델과 토크나이저를 불러오세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPTNeoForCausalLM, GPT2Tokenizer\n",
    "\n",
    "model = GPTNeoForCausalLM.from_pretrained(\"EleutherAI/gpt-neo-1.3B\")\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"EleutherAI/gpt-neo-1.3B\")\n",
    "\n",
    "prompt = (\n",
    "    \"혹시한국말도 알아듣니?.\"\n",
    ")\n",
    "\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "\n",
    "gen_tokens = model.generate(\n",
    "    input_ids,\n",
    "    do_sample=True,\n",
    "    temperature=0.9,\n",
    "    max_length=100,\n",
    ")\n",
    "gen_text = tokenizer.batch_decode(gen_tokens)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gpt-neo 계얼 모델 ElutherAI/ GPT Neo1.3B의 토크나이저를 사용해서 다음 문장을 인코딩하세요.\n",
    "\n",
    "반환 형식은 파이토치 텐서타입이어야 합니다.\n",
    "\n",
    "- I evaluated the performance of GPT-Neo developerd by OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> tensor([[  314, 16726,   262,  2854,   286,   402, 11571,    12,  8199,    78,\n",
      "          8517,    67,   416,  4946, 20185,    13,   383, 17019,  7686,   547,\n",
      "          8776,   329,  1160,    11,   830,  4831,    11,   290,   262,  2482,\n",
      "           547, 16726,   329,  1802,    11,   830,  4831,    13,  2293,  3047,\n",
      "           290,  4856,    11,   262,  1080,  8793,   257,  1029,  9922,   286,\n",
      "           657,    13,    22,  2598,    13,  2102,    11,   340,  9555,   257,\n",
      "          1877,  4049,  2494,   286,   860,    13,    19,     4,   706,   262,\n",
      "          1332,    13,   198,   198,     0,    58, 44154, 33222,   290, 46690,\n",
      "         13047,   329,   360, 14242,    12, 39764,  8808,    16,    13,    59,\n",
      "           198,  1890,  3047,    11,   356,   973,   360, 14242,    16,   329]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' I evaluated the performance of GPT-Neo developerd by OpenAI. The neural networks were trained for 20,000 steps, and the results were evaluated for 100,000 steps. After training and testing, the system achieved a high accuracy of 0.744. However, it demonstrated a low error rate of 9.4% after the test.\\n\\n![Testing Accuracy and Prediction Error for DAE-MNIST1.\\\\\\nFor training, we used DAE1 for'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "prompt = (\n",
    "    \" I evaluated the performance of GPT-Neo developerd by OpenAI.\"\n",
    ")\n",
    "\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "\n",
    "gen_tokens = model.generate(\n",
    "    input_ids,\n",
    "    do_sample=True,\n",
    "    temperature=0.9,\n",
    "    max_length=100,\n",
    ")\n",
    "print(type(gen_tokens), gen_tokens)\n",
    "gen_text = tokenizer.batch_decode(gen_tokens)[0]\n",
    "gen_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([   40, 16726,   262,  2854,   286,   402, 11571,    12,  8199,    78,\n",
      "         4166,   416,  4946, 20185,    13])\n",
      "I evaluated the performance of GPT-Neo developed by OpenAI.\n"
     ]
    }
   ],
   "source": [
    "input = tokenizer.encode(\"I evaluated the performance of GPT-Neo developed by OpenAI.\", return_tensors='pt')\n",
    "\n",
    "print(input[0])\n",
    "print(tokenizer.decode(input[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   40, 16726,   262,  2854,   286,   402, 11571,    12,  8199,    78,\n",
      "          1205,   416,  4946, 20185,    13],\n",
      "        [   40, 16726,   262,  2854,   286,   402, 11571,  4166,   416,  4946,\n",
      "         20185, 50257, 50257, 50257, 50257]])\n",
      "['I evaluated the performance of GPT-Neo develop by OpenAI.', 'I evaluated the performance of GPT developed by OpenAI[PAD][PAD][PAD][PAD]']\n"
     ]
    }
   ],
   "source": [
    "# 두 개 이상의 문장을 인코딩 하기 위해서, pad_token을 설정한 후 padding=True, truncation=True\n",
    "# 설정값을 가진 tokenizer.batch_encoder_plus()를 사용\n",
    "\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "\n",
    "input = tokenizer.batch_encode_plus(\n",
    "    ['I evaluated the performance of GPT-Neo develop by OpenAI.',\n",
    "    \"I evaluated the performance of GPT developed by OpenAI\"],\n",
    "    padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "# 인코딩\n",
    "print(input['input_ids'])\n",
    "\n",
    "# 디코딩\n",
    "print([\n",
    "    tokenizer.decode(input['input_ids'][i]) for i in range(len(input['input_ids']))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@#@# tensor([[   40, 16726,   262,  2854,   286,   402, 11571,    12,  8199,    78,\n",
      "          1205,   416,  4946, 20185,    13],\n",
      "        [   40, 16726,   262,  2854,   286,   402, 11571,  4166,   416,  4946,\n",
      "         20185, 50257, 50257, 50257, 50257]])\n",
      " I evaluated the performance of GPT-Neo developerd by OpenAI. The time required to produce a video is more than 40 hours for the whole development process. GPT\n"
     ]
    }
   ],
   "source": [
    "print(\"@#@#\", input['input_ids'])\n",
    "gen_tokens = model.generate(\n",
    "    input_ids,\n",
    "    do_sample=True\n",
    ")\n",
    "gen_text = tokenizer.batch_decode(gen_tokens)[0]\n",
    "\n",
    "print(gen_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
